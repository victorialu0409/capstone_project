{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "674b9e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.Undersampling \n",
    "#2.Oversampling \n",
    "#3.SMOTE\n",
    "#4.Ensemble Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "e51b9b66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   status_label  Current_Ratio  Quick_Ratio  Gross_Profit_Margin  \\\n",
      "0             1       2.828383     1.184518            19.167191   \n",
      "1             1       0.848425     0.606935            41.189988   \n",
      "2             1       2.880662     2.830330            62.776229   \n",
      "3             1       1.405975     1.405975            68.751104   \n",
      "4             1       1.411216     0.655987             5.729787   \n",
      "\n",
      "   Net_Income_Margin  Return_on_Assets  Return_on_Equity  \\\n",
      "0           0.892295          1.023152          1.666133   \n",
      "1          13.700293          2.870049          9.510936   \n",
      "2          36.223372          8.490236          9.246249   \n",
      "3          37.201908         24.293459        118.248175   \n",
      "4           0.972325          3.869466         12.264547   \n",
      "\n",
      "   Debt_to_Assets_Ratio  Interest_Coverage_Ratio  Debt_to_EBITDA_Ratio  ...  \\\n",
      "0              0.116226                 0.485300              2.060581  ...   \n",
      "1              0.281433                 0.195090              5.125840  ...   \n",
      "2              0.000117               648.900000              0.001541  ...   \n",
      "3              0.411121                 0.655161              1.526343  ...   \n",
      "4              0.103600                 0.641421              1.559038  ...   \n",
      "\n",
      "   Inventory_Turnover_Ratio  Receivables_Turnover_Ratio  \\\n",
      "0                  3.190853                    8.611891   \n",
      "1                 12.324723                    8.589460   \n",
      "2                 62.787500                    8.997761   \n",
      "3             566100.000000                    5.045410   \n",
      "4                  9.484550                   12.431862   \n",
      "\n",
      "   Fixed_Asset_Turnover_Ratio  Accounts_Payable_Turnover_Ratio  \\\n",
      "0                    3.003900                        -8.147164   \n",
      "1                    0.222792                         3.923979   \n",
      "2                    0.295514                         3.429254   \n",
      "3                    1.132651                         2.168127   \n",
      "4                   18.427194                        29.264054   \n",
      "\n",
      "   Operating_Profit_Margin  EBITDA_Margin  EBIT_Margin  Price_to_Book_Ratio  \\\n",
      "0                 4.919064       7.235600     4.919064          2570.780653   \n",
      "1                26.208960      41.189988    26.208960         17643.457687   \n",
      "2                32.296436      55.499701    32.296436           209.315854   \n",
      "3                41.247129      44.444444    41.247129        433236.418735   \n",
      "4                 1.669795       1.878825     1.669795         11637.854580   \n",
      "\n",
      "   EV_to_EBITDA_Ratio  cycle_type  \n",
      "0           13.333233           1  \n",
      "1           -1.812924           1  \n",
      "2            9.304731           0  \n",
      "3           11.282048           1  \n",
      "4            5.920336           0  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Read data\n",
    "df = pd.read_csv(\"/Users/victorialu/Desktop/Datasets/cleaned_bankruptcy.csv\")\n",
    "print(df[:5])\n",
    "df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "31c1e57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8465, 22)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "5aac4a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    786\n",
      "0     60\n",
      "Name: status_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Testint set-containing 10% 0s and 10% 1s from the original dataset\n",
    "\n",
    "#separate the positive and negative samples\n",
    "pos_data = df[df['status_label'] == 1]\n",
    "neg_data = df[df['status_label'] == 0]\n",
    "\n",
    "#sample 10% of positive and negative samples\n",
    "np.random.seed(567) \n",
    "pos_holdout_index = np.random.choice(pos_data.index, int(len(pos_data) * 0.1), replace=False)\n",
    "neg_holdout_index = np.random.choice(neg_data.index, int(len(neg_data) * 0.1), replace=False)\n",
    "\n",
    "#create the holdout indices\n",
    "holdout_pos = pos_data.loc[pos_holdout_index]\n",
    "holdout_neg = neg_data.loc[neg_holdout_index]\n",
    "\n",
    "#concatenate to form final holdout sets\n",
    "bankrupt_test = pd.concat([holdout_pos, holdout_neg])\n",
    "bankrupt_test.shape\n",
    "class_distribution = bankrupt_test[\"status_label\"].value_counts()\n",
    "print(class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "77751181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7619, 21)\n",
      "(7619,)\n",
      "(846, 21)\n",
      "(846,)\n"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "training_pos = pos_data.drop(index=pos_holdout_index)\n",
    "training_neg = neg_data.drop(index=neg_holdout_index)\n",
    "\n",
    "bankrupt_train = pd.concat([training_pos, training_neg])\n",
    "\n",
    "X_train = bankrupt_train.drop(columns=['status_label'])\n",
    "y_train = bankrupt_train['status_label']\n",
    "X_test = bankrupt_test.drop(columns=['status_label'])\n",
    "y_test = bankrupt_test['status_label']\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "defca9aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Class Distribution:\n",
      "1    7076\n",
      "0     543\n",
      "Name: status_label, dtype: int64\n",
      "\n",
      "Testing Set Class Distribution:\n",
      "1    786\n",
      "0     60\n",
      "Name: status_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Class dist. for training and testing\n",
    "train_class_distribution = y_train.value_counts()\n",
    "print(\"Training Set Class Distribution:\")\n",
    "print(train_class_distribution)\n",
    "\n",
    "test_class_distribution = y_test.value_counts()\n",
    "print(\"\\nTesting Set Class Distribution:\")\n",
    "print(test_class_distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "ad421f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate majority and minority classes\n",
    "minority_class = bankrupt_train[bankrupt_train['status_label'] == 0]\n",
    "majority_class = bankrupt_train[bankrupt_train['status_label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "5d38a8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "desired_ratio = 1\n",
    "num_samples = len(minority_class) * desired_ratio\n",
    "\n",
    "# Perform random undersampling on the majority class\n",
    "undersampled_majority = resample(majority_class, n_samples=num_samples, random_state=1)\n",
    "\n",
    "# Combine the classes\n",
    "undersampled_data = pd.concat([undersampled_majority, minority_class])\n",
    "\n",
    "# Split the undersampled data back into X_train and y_train\n",
    "X_train_undersampled = undersampled_data.drop(columns=['status_label'])\n",
    "y_train_undersampled = undersampled_data['status_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "abe542c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    543\n",
      "0    543\n",
      "Name: status_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = pd.value_counts(y_train_undersampled) \n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "6b515d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Oversampling #########\n",
    "desired_ratio = 1\n",
    "num_samples = len(majority_class) * desired_ratio\n",
    "\n",
    "#perform random oversampling on the minority class\n",
    "oversampled_minority = resample(minority_class, n_samples=num_samples, random_state=1)\n",
    "\n",
    "#combine the classes \n",
    "oversampled_data = pd.concat([majority_class, oversampled_minority])\n",
    "\n",
    "X_train_oversampled = oversampled_data.drop(columns=['status_label'])\n",
    "y_train_oversampled = oversampled_data['status_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "27432a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    7076\n",
      "0    7076\n",
      "Name: status_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = pd.value_counts(y_train_oversampled) \n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "2de651b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "######### SMOTE #########\n",
    "#!pip install -U imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "61cd0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "35362614",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the SMOTE resampler\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=1) # auto-1:1 oversampling\n",
    "X_train_smote, y_train_smote = smote.fit_resample(bankrupt_train.drop('status_label', axis=1), bankrupt_train['status_label'])\n",
    "\n",
    "\n",
    "X_train_smote = pd.DataFrame(X_train_smote)\n",
    "y_train_smote = pd.Series(y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "aad383e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    7076\n",
      "0    7076\n",
      "Name: status_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = pd.value_counts(y_train_smote) \n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "6f62f093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 4, 1]\n"
     ]
    }
   ],
   "source": [
    "######### Ensemble Method #########\n",
    "#create three separate balanced datasets-majority vote when making predictions\n",
    "\n",
    "#define a function to get a batch of training data with varying class distributions\n",
    "def get_train_batch(df_majority, df_minority, start, end):\n",
    "    df_train = pd.concat([df_majority[start:end], df_minority], axis=0)\n",
    "\n",
    "    X_train = df_train.drop('status_label', axis='columns')\n",
    "    y_train = df_train['status_label']\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "#6298/474 = 13-can generate 12 models\n",
    "#randomly choose 3\n",
    "import random\n",
    "\n",
    "def generate_unique_random_numbers(seed=None):        \n",
    "    if seed is not None:\n",
    "        random.seed(seed)\n",
    "        \n",
    "    #generate a list of three unique random numbers between 0 and 12\n",
    "    return random.sample(range(13), 3)\n",
    "\n",
    "random_num = generate_unique_random_numbers(seed=123)\n",
    "print(random_num)\n",
    "\n",
    "X_train_edata1, y_train_edata1 = get_train_batch(majority_class, minority_class, random_num[0]*len(minority_class), \n",
    "                                                 random_num[0]*len(minority_class)+len(minority_class))\n",
    "X_train_edata2, y_train_edata2 = get_train_batch(majority_class, minority_class, random_num[1]*len(minority_class), \n",
    "                                                 random_num[1]*len(minority_class)+len(minority_class))\n",
    "X_train_edata3, y_train_edata3 = get_train_batch(majority_class, minority_class, random_num[2]*len(minority_class), \n",
    "                                                 random_num[2]*len(minority_class)+len(minority_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "acd3a405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    543\n",
      "0    543\n",
      "Name: status_label, dtype: int64\n",
      "1    543\n",
      "0    543\n",
      "Name: status_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "value_counts = pd.value_counts(y_train_edata1) \n",
    "print(value_counts)\n",
    "value_counts = pd.value_counts(y_train_edata2) \n",
    "print(value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "655ea37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy pandas xgboost scikit-learn\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "\n",
    "\n",
    "def evaluate_xgboost(X_train, y_train, X_test, y_test):\n",
    "    #initialize the XGBoost classifier\n",
    "    xgb = XGBClassifier(random_state=123)\n",
    "    \n",
    "    xgb.fit(X_train, y_train)\n",
    "    \n",
    "    ##########\n",
    "    #get predicted probabilities for class 1\n",
    "    y_pred_prob = xgb.predict_proba(X_test)[:, 1]\n",
    "    print(y_pred_prob)\n",
    "    \n",
    "    #adjust the threshold\n",
    "    y_pred = (y_pred_prob >= 0.50).astype(int)\n",
    "    \n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    sensitivity = recall_score(y_test, y_pred)\n",
    "    specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "    misclass = 1 - accuracy_score(y_test, y_pred)\n",
    "    return sensitivity, specificity, misclass\n",
    "\n",
    "# Sensitivity: If good at identifying alive companies \n",
    "# Specificity: Correctly predicted bankrupt companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "ec740ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99917006 0.9929295  0.98727477 0.878097   0.992961   0.9968189\n",
      " 0.9656749  0.9971079  0.9923201  0.9755955  0.9698741  0.9650643\n",
      " 0.70485127 0.99907935 0.5261377  0.96194404 0.9958313  0.92316383\n",
      " 0.8884994  0.9946938  0.998923   0.999742   0.9967817  0.9975605\n",
      " 0.99433714 0.95793873 0.91729796 0.99858284 0.99068624 0.9781148\n",
      " 0.9886474  0.99855024 0.99850297 0.99788624 0.9952355  0.93967056\n",
      " 0.99904436 0.91058713 0.9887644  0.8345164  0.9945293  0.97174555\n",
      " 0.83484185 0.99939144 0.9813835  0.95088136 0.9517599  0.96670467\n",
      " 0.9956969  0.99804723 0.9990533  0.9987225  0.999642   0.9973133\n",
      " 0.9986035  0.9937761  0.9901286  0.93692803 0.92658657 0.8186249\n",
      " 0.98275465 0.9758695  0.924284   0.8951169  0.9658663  0.9260426\n",
      " 0.65396327 0.9583694  0.99865437 0.99295384 0.98486334 0.9741769\n",
      " 0.9393638  0.99593097 0.997776   0.98996174 0.9964103  0.9964072\n",
      " 0.99056715 0.9987771  0.9113033  0.98741907 0.91456205 0.98224026\n",
      " 0.9475575  0.7924257  0.97894764 0.9547751  0.96190524 0.99926645\n",
      " 0.9920127  0.9995266  0.99702185 0.9932728  0.99659866 0.98509234\n",
      " 0.9960731  0.99615186 0.97552323 0.9985838  0.97404057 0.98090553\n",
      " 0.98644143 0.9985147  0.9588529  0.9512401  0.99801695 0.9995758\n",
      " 0.99585056 0.9981918  0.9722086  0.99663156 0.9834431  0.9856456\n",
      " 0.97741115 0.98105514 0.9907616  0.8408009  0.998865   0.9797831\n",
      " 0.9958294  0.9980683  0.43428066 0.6291815  0.98098963 0.99716693\n",
      " 0.94621634 0.9970674  0.9751448  0.95262325 0.99320686 0.9259168\n",
      " 0.9821308  0.9572573  0.9739013  0.9834011  0.97635853 0.61320335\n",
      " 0.91736835 0.9976076  0.9926763  0.99344915 0.96273893 0.7091762\n",
      " 0.97615427 0.9924556  0.9872119  0.94560933 0.9450188  0.9869032\n",
      " 0.9956013  0.61431295 0.8651412  0.9997092  0.94369715 0.84312856\n",
      " 0.99574345 0.99796826 0.9995653  0.91736346 0.9966813  0.999408\n",
      " 0.9921699  0.9980579  0.98232734 0.76810056 0.9884233  0.9980464\n",
      " 0.98987484 0.97757727 0.99454236 0.9952118  0.99887055 0.99874026\n",
      " 0.9866362  0.99843067 0.9663666  0.99022466 0.99966955 0.9993388\n",
      " 0.9981775  0.9685838  0.9798226  0.9760174  0.8522591  0.98827165\n",
      " 0.9646805  0.7374969  0.9967796  0.96993184 0.98219115 0.99451584\n",
      " 0.9507761  0.95221454 0.71208704 0.99150777 0.69094306 0.97212327\n",
      " 0.9937973  0.9484275  0.95679355 0.9582477  0.9664139  0.9757735\n",
      " 0.96258765 0.9765387  0.6844057  0.9499935  0.9918888  0.99952686\n",
      " 0.99710053 0.9872939  0.9887427  0.99704176 0.9975184  0.9998115\n",
      " 0.99975246 0.9971433  0.9585385  0.97469145 0.98823357 0.9584178\n",
      " 0.9773916  0.9946471  0.9871509  0.9996284  0.99445987 0.9952859\n",
      " 0.9740979  0.994241   0.9997414  0.9916294  0.9990534  0.99219066\n",
      " 0.9898078  0.9974934  0.86536413 0.9978022  0.98250085 0.9954755\n",
      " 0.92485607 0.9931405  0.9898044  0.98737293 0.9964084  0.9958968\n",
      " 0.935706   0.96790946 0.96336097 0.9940859  0.9942807  0.97716516\n",
      " 0.9914215  0.97973037 0.9977603  0.9928023  0.99407274 0.99361926\n",
      " 0.9910362  0.9531833  0.9231397  0.98408645 0.9609229  0.9982241\n",
      " 0.99844104 0.8060762  0.99892646 0.998998   0.98288214 0.9037475\n",
      " 0.99651295 0.96081215 0.99962544 0.8986829  0.99363697 0.9506459\n",
      " 0.99510753 0.99509573 0.914844   0.9998653  0.98376197 0.9878157\n",
      " 0.99921083 0.9687178  0.9953982  0.9981731  0.9891216  0.9255771\n",
      " 0.9980404  0.98799753 0.83786047 0.99284345 0.99223024 0.98392063\n",
      " 0.98383105 0.99405885 0.9994423  0.99649686 0.9547717  0.9927004\n",
      " 0.98383695 0.89842445 0.9930299  0.9977047  0.963442   0.9933838\n",
      " 0.71007067 0.58885425 0.9906798  0.9927066  0.9512966  0.98800695\n",
      " 0.97422135 0.916936   0.99258995 0.99833626 0.99126804 0.9695836\n",
      " 0.92456484 0.95931697 0.92692935 0.995765   0.9502776  0.9905595\n",
      " 0.99892265 0.9962353  0.91102785 0.9311518  0.9989291  0.99796754\n",
      " 0.99706    0.9981572  0.9990501  0.99273384 0.79919213 0.9896366\n",
      " 0.9777785  0.9991943  0.9693876  0.9900851  0.9942437  0.99027073\n",
      " 0.9988262  0.9737204  0.99976057 0.99650323 0.95988566 0.9991406\n",
      " 0.9823455  0.8248808  0.9863424  0.99977463 0.99168396 0.95536816\n",
      " 0.99856913 0.98550767 0.9992393  0.93356395 0.97422475 0.93093634\n",
      " 0.995272   0.9265857  0.9930936  0.99540544 0.8328405  0.46541208\n",
      " 0.9994344  0.9996227  0.9966274  0.9899935  0.9759076  0.9958489\n",
      " 0.9972262  0.94160086 0.686751   0.94012475 0.99279034 0.9396799\n",
      " 0.97737086 0.9771903  0.9952508  0.98873425 0.9998901  0.92689764\n",
      " 0.98056567 0.96776706 0.98282444 0.9909958  0.7670237  0.8311397\n",
      " 0.98888165 0.999892   0.9831028  0.9995466  0.8347515  0.9905539\n",
      " 0.9467628  0.97991586 0.9648565  0.93768704 0.9874407  0.9905261\n",
      " 0.93720394 0.9480124  0.9941953  0.997815   0.99875546 0.99529946\n",
      " 0.93197477 0.9958729  0.9871836  0.9460726  0.99895406 0.9978811\n",
      " 0.99721164 0.9733844  0.99191004 0.9972452  0.62621295 0.9999249\n",
      " 0.9883748  0.967766   0.99840987 0.9662706  0.98260444 0.99896896\n",
      " 0.9884515  0.99980587 0.9992933  0.99751234 0.99268734 0.991755\n",
      " 0.9933082  0.94804764 0.9971214  0.97310567 0.99978703 0.98323387\n",
      " 0.99871385 0.9959319  0.9912479  0.9977647  0.9900581  0.9988945\n",
      " 0.99444866 0.9973621  0.998245   0.99045396 0.9950305  0.99644464\n",
      " 0.99487644 0.9981536  0.99749655 0.99935955 0.8818455  0.9791967\n",
      " 0.9966754  0.9722001  0.9065976  0.9822083  0.9914967  0.9987196\n",
      " 0.97647005 0.9983877  0.9789778  0.9997466  0.9981122  0.93420345\n",
      " 0.9895197  0.9866916  0.9973544  0.7962545  0.8118446  0.9749257\n",
      " 0.9398521  0.94380885 0.92799795 0.98750407 0.9806526  0.9972325\n",
      " 0.9648053  0.9547238  0.94931686 0.9972669  0.96515036 0.962787\n",
      " 0.996763   0.82157874 0.9946056  0.9882958  0.90896463 0.6771659\n",
      " 0.96227056 0.9502028  0.9977487  0.99202114 0.9956197  0.6594701\n",
      " 0.99581003 0.9853829  0.9989579  0.9961964  0.99406767 0.9989802\n",
      " 0.99280167 0.85060096 0.9941906  0.9920035  0.9988612  0.93262964\n",
      " 0.98774594 0.9861167  0.999137   0.9714271  0.95072186 0.94775885\n",
      " 0.9888215  0.9992331  0.8449673  0.9485682  0.97636503 0.9986085\n",
      " 0.99930954 0.72111064 0.9966568  0.9926076  0.82507664 0.99773765\n",
      " 0.7487168  0.99882275 0.9391941  0.98903173 0.9986613  0.97671574\n",
      " 0.9828818  0.9974394  0.99026275 0.98883677 0.98989725 0.9973545\n",
      " 0.9970854  0.99486685 0.97030175 0.9975055  0.9896569  0.9944289\n",
      " 0.99733233 0.99787354 0.99833626 0.9971334  0.9499694  0.9974058\n",
      " 0.9994598  0.99754554 0.998162   0.834003   0.9610409  0.9987557\n",
      " 0.9434104  0.963616   0.9985176  0.91187024 0.999159   0.9876287\n",
      " 0.9848358  0.9994259  0.9966738  0.99924326 0.97982085 0.9880385\n",
      " 0.99751943 0.9948407  0.9994106  0.9360727  0.977027   0.9774278\n",
      " 0.9588452  0.9993111  0.99837315 0.99564457 0.9994092  0.9949675\n",
      " 0.94570667 0.9689306  0.98059213 0.9834547  0.9964038  0.9935348\n",
      " 0.99718094 0.9989304  0.988112   0.9973289  0.80906045 0.99593157\n",
      " 0.8835682  0.889874   0.999238   0.99920887 0.9855236  0.98471284\n",
      " 0.99590623 0.9888497  0.9980038  0.9000092  0.997584   0.9469159\n",
      " 0.9976342  0.998771   0.9896402  0.99785334 0.85342336 0.9995503\n",
      " 0.97835594 0.99450594 0.9993556  0.99075645 0.98126125 0.99734807\n",
      " 0.71544117 0.991542   0.9367689  0.9964923  0.9840126  0.96406275\n",
      " 0.92758423 0.80160046 0.6293149  0.97305626 0.98627627 0.98598623\n",
      " 0.98236775 0.99106103 0.9443515  0.99093586 0.9996916  0.98916316\n",
      " 0.9995623  0.99945015 0.9477276  0.9980908  0.99275887 0.9968546\n",
      " 0.99857223 0.98990554 0.96690136 0.85559374 0.8414298  0.99805707\n",
      " 0.8871059  0.96248674 0.9688476  0.8857958  0.9994863  0.9738853\n",
      " 0.99354976 0.9850856  0.96457815 0.98854023 0.9589433  0.91130745\n",
      " 0.9996493  0.9254646  0.9995314  0.99673516 0.98567957 0.9968267\n",
      " 0.99943656 0.99356765 0.9866861  0.99775404 0.98457307 0.97906876\n",
      " 0.85870767 0.9969823  0.999509   0.9998198  0.9968078  0.9787851\n",
      " 0.9653298  0.9994123  0.85855246 0.9960653  0.99289274 0.9993709\n",
      " 0.97443557 0.99968994 0.9661993  0.9202389  0.9398507  0.9481174\n",
      " 0.9051726  0.996366   0.9978369  0.70430386 0.99475163 0.958465\n",
      " 0.9941755  0.9847644  0.93041945 0.9940236  0.98267305 0.9983271\n",
      " 0.9050764  0.974875   0.9967699  0.9840013  0.9953636  0.99840987\n",
      " 0.9961283  0.9833018  0.99401385 0.98541147 0.99916315 0.99897575\n",
      " 0.9970931  0.8926183  0.97446793 0.99752337 0.99889696 0.9419321\n",
      " 0.93499637 0.9967669  0.97244644 0.99693584 0.9887744  0.88877475\n",
      " 0.9916488  0.9852107  0.9732651  0.9591406  0.96585435 0.9985814\n",
      " 0.9867578  0.9487728  0.994503   0.963368   0.9891423  0.99832803\n",
      " 0.99385697 0.9711006  0.9657817  0.98130924 0.998173   0.99094605\n",
      " 0.9966221  0.9914621  0.997486   0.6000594  0.99021775 0.9669234\n",
      " 0.99864715 0.99149114 0.99977714 0.97769356 0.952402   0.95573723\n",
      " 0.98922837 0.9764786  0.98828655 0.99427855 0.99517304 0.9742389\n",
      " 0.7417345  0.8581555  0.99925286 0.9483549  0.9986003  0.9864807\n",
      " 0.9976909  0.9362756  0.9871997  0.99559647 0.9308578  0.99781585\n",
      " 0.98849946 0.9973333  0.9950688  0.9965628  0.99938726 0.9989975\n",
      " 0.9420439  0.9989115  0.99419844 0.9812774  0.9584528  0.99843293\n",
      " 0.85417724 0.67300296 0.99789184 0.99394494 0.9446817  0.84221625\n",
      " 0.86648726 0.47008696 0.80027413 0.99825805 0.97008735 0.9764056\n",
      " 0.9960394  0.95585346 0.98939764 0.9681451  0.9597356  0.988492\n",
      " 0.9793139  0.9108428  0.9930235  0.99444073 0.8183884  0.71866924\n",
      " 0.95385706 0.9878369  0.91407907 0.99496955 0.8863786  0.99922144\n",
      " 0.5813173  0.67899203 0.9849341  0.65994006 0.9451664  0.9822171\n",
      " 0.98459136 0.96903    0.8028195  0.7883247  0.9545376  0.8836765\n",
      " 0.93733037 0.7546535  0.84117687 0.9221493  0.9760543  0.9855113\n",
      " 0.9189761  0.99721366 0.7022174  0.95335716 0.9997259  0.6577966\n",
      " 0.96621567 0.97143316 0.9633636  0.9918304  0.8626788  0.985284  ]\n",
      "metrics 0.9974554707379135 0.016666666666666666 0.0721040189125296\n"
     ]
    }
   ],
   "source": [
    "# Comparing model performance on different training sets\n",
    "# Unbalanced data\n",
    "sensitivity, specificity, misclass = evaluate_xgboost(X_train, y_train, X_test, y_test)\n",
    "print('metrics', sensitivity, specificity, misclass)\n",
    "#0.9974554707379135 0.016666666666666666 0.0721040189125296"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "97d96135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.94460773 0.4155201  0.5693606  0.02686688 0.60274947 0.9993166\n",
      " 0.10579599 0.9727585  0.35946462 0.02035164 0.64111453 0.1086268\n",
      " 0.05155915 0.9577952  0.0410782  0.27768975 0.9966304  0.06385197\n",
      " 0.38207445 0.9660016  0.8824126  0.99908435 0.55610144 0.9769135\n",
      " 0.5177677  0.4148035  0.07862664 0.8712629  0.8493357  0.5840977\n",
      " 0.95262444 0.93786156 0.9522608  0.9612885  0.10942335 0.44481143\n",
      " 0.94249237 0.5876088  0.09257105 0.569048   0.7998267  0.03535303\n",
      " 0.10726528 0.9765496  0.04335463 0.18106246 0.93743455 0.02823821\n",
      " 0.9672998  0.6032664  0.9414748  0.527022   0.99713683 0.92212325\n",
      " 0.98900455 0.39770633 0.9569418  0.020941   0.01638636 0.15633394\n",
      " 0.18464176 0.9179416  0.05602549 0.5599025  0.98758626 0.01805872\n",
      " 0.633666   0.1560526  0.9850503  0.99588275 0.98801315 0.24627659\n",
      " 0.21687971 0.90194654 0.8962776  0.5699415  0.78768975 0.55982596\n",
      " 0.32982215 0.27411607 0.22555725 0.22093531 0.6953764  0.92366225\n",
      " 0.9338383  0.0045768  0.83239526 0.7685037  0.27884743 0.8655449\n",
      " 0.98053545 0.96038175 0.80801827 0.99829954 0.77843684 0.5565696\n",
      " 0.7278028  0.09086329 0.47282055 0.839501   0.8698784  0.71739775\n",
      " 0.9872732  0.988064   0.09898221 0.20163342 0.90944016 0.9922085\n",
      " 0.9728195  0.99426275 0.02093831 0.9933947  0.9597537  0.7097821\n",
      " 0.67588174 0.47427264 0.27534848 0.6786301  0.47116742 0.8896338\n",
      " 0.7802892  0.12474471 0.16480649 0.61151254 0.20367746 0.7419109\n",
      " 0.63261455 0.84049195 0.96123636 0.67507    0.93156886 0.5859102\n",
      " 0.26497006 0.16207737 0.39353487 0.26766068 0.39471337 0.02329828\n",
      " 0.09193513 0.35505593 0.06991715 0.8974196  0.25701547 0.01287891\n",
      " 0.16302392 0.80849874 0.86165315 0.11787833 0.02467082 0.630694\n",
      " 0.9451782  0.1201485  0.03250873 0.9833507  0.18652138 0.6793061\n",
      " 0.9887766  0.96607965 0.99450916 0.20096047 0.8473864  0.9652546\n",
      " 0.44471195 0.2632482  0.83066684 0.42283323 0.6243214  0.91412085\n",
      " 0.9455278  0.3604355  0.7586663  0.98828053 0.9399908  0.9976629\n",
      " 0.92128485 0.9064061  0.05399273 0.77466244 0.99785256 0.88547754\n",
      " 0.588862   0.34687027 0.1200003  0.93232375 0.10721545 0.73335034\n",
      " 0.9168054  0.07472438 0.86595845 0.8532413  0.86338836 0.8589576\n",
      " 0.32712582 0.248873   0.01049012 0.40027416 0.12340939 0.6295675\n",
      " 0.94615006 0.8509834  0.4590306  0.8832531  0.6936685  0.27654466\n",
      " 0.43389118 0.3017012  0.00862708 0.45913202 0.09363625 0.99475336\n",
      " 0.57114726 0.8692768  0.9650621  0.9746703  0.6647965  0.9970553\n",
      " 0.9694141  0.4535683  0.119217   0.94424015 0.03340936 0.04887122\n",
      " 0.8438784  0.7858568  0.53534156 0.8725729  0.6084269  0.9936731\n",
      " 0.01346817 0.92222184 0.9485458  0.9871973  0.8114645  0.6600301\n",
      " 0.30548725 0.98523486 0.20241943 0.81438327 0.00573803 0.98579305\n",
      " 0.77401465 0.3112408  0.5639855  0.66372895 0.88835496 0.88521415\n",
      " 0.3482117  0.642874   0.44563237 0.88112843 0.5684269  0.39214465\n",
      " 0.44212052 0.19646811 0.9154361  0.4261271  0.13117065 0.58496773\n",
      " 0.6426614  0.7573577  0.60441977 0.7676394  0.14293285 0.94631904\n",
      " 0.9890966  0.10337912 0.95275354 0.9738139  0.5321925  0.39074376\n",
      " 0.9239431  0.4166683  0.95397085 0.879607   0.20988739 0.6060404\n",
      " 0.9817129  0.85190576 0.1326391  0.9967264  0.31669644 0.158448\n",
      " 0.93525124 0.5829968  0.5499224  0.8584846  0.84862626 0.14957437\n",
      " 0.75493956 0.943909   0.3248455  0.52174574 0.8509829  0.93812144\n",
      " 0.9511974  0.97933674 0.99595934 0.99251854 0.1408167  0.04033753\n",
      " 0.03543839 0.05108845 0.9788699  0.94471276 0.00959843 0.44751105\n",
      " 0.07049204 0.02647452 0.39189032 0.74871916 0.9070031  0.32134897\n",
      " 0.2291974  0.33765197 0.64987165 0.4577948  0.8503187  0.9285565\n",
      " 0.2609607  0.22391401 0.36233452 0.99650145 0.08468409 0.9058835\n",
      " 0.81176    0.9860721  0.08101716 0.8916596  0.9858051  0.96401566\n",
      " 0.6610502  0.10878448 0.9509228  0.2366595  0.14107586 0.07208104\n",
      " 0.09338912 0.91853327 0.10680367 0.7873452  0.03806495 0.0584982\n",
      " 0.9723857  0.07282615 0.96110874 0.8775297  0.11320079 0.87942606\n",
      " 0.33680305 0.00450769 0.13318    0.97338605 0.97190505 0.5292352\n",
      " 0.9963574  0.11759342 0.7782743  0.09965686 0.85107887 0.0786125\n",
      " 0.18339238 0.3224908  0.70422196 0.7974215  0.03659663 0.2840727\n",
      " 0.9152208  0.99028265 0.8321887  0.8198325  0.7727026  0.1984953\n",
      " 0.3504988  0.04641042 0.04857965 0.02437098 0.91524464 0.49968892\n",
      " 0.12246874 0.42776236 0.23429015 0.9082576  0.99845266 0.26860318\n",
      " 0.7700096  0.18841219 0.3984455  0.99070907 0.02951145 0.04065479\n",
      " 0.2903176  0.76775265 0.4431571  0.85821414 0.02267738 0.43073398\n",
      " 0.12116675 0.42286968 0.8688908  0.48412773 0.28869003 0.5758092\n",
      " 0.04935841 0.21058281 0.87964576 0.8391431  0.9941229  0.9568164\n",
      " 0.11372684 0.9602474  0.91806906 0.44232243 0.91834503 0.8251397\n",
      " 0.4534469  0.49512663 0.64696413 0.92509544 0.01494163 0.9250078\n",
      " 0.8971619  0.00768162 0.9283642  0.69893026 0.09558588 0.9768594\n",
      " 0.8378926  0.99920744 0.99064213 0.9951904  0.0178826  0.5463582\n",
      " 0.76459646 0.41124853 0.5611778  0.40967718 0.9570122  0.5953509\n",
      " 0.6037524  0.68739897 0.92278427 0.58680224 0.77193207 0.44646567\n",
      " 0.23828313 0.9870046  0.929441   0.8894457  0.51829904 0.9958034\n",
      " 0.88494986 0.81934696 0.7173796  0.9925809  0.8382955  0.5904705\n",
      " 0.6352345  0.40606746 0.18030581 0.05651503 0.79905033 0.9154841\n",
      " 0.32585967 0.667271   0.1600257  0.94806457 0.96159834 0.12557983\n",
      " 0.1334464  0.99738055 0.86029834 0.66304505 0.13121632 0.30489492\n",
      " 0.05787393 0.68761504 0.46578908 0.7160906  0.216965   0.91309345\n",
      " 0.5351195  0.83512944 0.9145374  0.9601608  0.14330018 0.60174894\n",
      " 0.6645853  0.36148208 0.22732216 0.23456757 0.6523578  0.28851622\n",
      " 0.3710923  0.35819343 0.93982255 0.07898137 0.9258803  0.18106416\n",
      " 0.9129901  0.05503818 0.98947924 0.966714   0.9599646  0.98790914\n",
      " 0.6497035  0.22920443 0.38639906 0.5713706  0.9216611  0.41127104\n",
      " 0.28015146 0.20517589 0.89503276 0.23782724 0.09454354 0.16011068\n",
      " 0.45451546 0.94150466 0.0193562  0.7597502  0.95456874 0.50222594\n",
      " 0.99224514 0.05902553 0.36803606 0.4790199  0.01676799 0.7480727\n",
      " 0.34866214 0.8496846  0.89159536 0.42788804 0.7618318  0.5429232\n",
      " 0.20829426 0.9938111  0.69444454 0.5053669  0.65943915 0.9968567\n",
      " 0.8827638  0.9413274  0.4240241  0.7011497  0.6243262  0.92727786\n",
      " 0.34298685 0.99358857 0.7848649  0.9413329  0.5352759  0.95777816\n",
      " 0.32060537 0.9506916  0.9613287  0.26440957 0.14360218 0.24111974\n",
      " 0.01367792 0.12362892 0.8406736  0.15781304 0.9758985  0.8776225\n",
      " 0.7202838  0.9986841  0.9887897  0.7356291  0.13632894 0.77842164\n",
      " 0.9968546  0.42339966 0.9936924  0.32224905 0.82810414 0.27424216\n",
      " 0.10686551 0.9370574  0.9754911  0.91425    0.98493606 0.8349331\n",
      " 0.66205335 0.8121684  0.18700492 0.4089844  0.9238901  0.49081394\n",
      " 0.46856612 0.9739096  0.05748755 0.9368688  0.15774958 0.5893414\n",
      " 0.14002499 0.00653624 0.89190716 0.8858745  0.39134818 0.88346535\n",
      " 0.6350683  0.06111493 0.69382113 0.2043381  0.9775274  0.06209593\n",
      " 0.88557994 0.9183254  0.9931838  0.86109185 0.4962143  0.956612\n",
      " 0.64494526 0.73001283 0.9839199  0.91335    0.15452549 0.37918374\n",
      " 0.06015695 0.10999715 0.03388412 0.9689837  0.7720614  0.47693253\n",
      " 0.09787148 0.02838901 0.07036293 0.07767004 0.78451437 0.8715467\n",
      " 0.27921766 0.81014615 0.25794578 0.77167463 0.99530894 0.08591267\n",
      " 0.94102716 0.9984382  0.28697205 0.9237652  0.95424247 0.3702166\n",
      " 0.9835293  0.9484805  0.11036178 0.08866441 0.04787684 0.9804451\n",
      " 0.35728684 0.12461263 0.16239499 0.801744   0.9979463  0.19055267\n",
      " 0.7896759  0.87248635 0.96717346 0.42431116 0.7915593  0.13297251\n",
      " 0.85380775 0.02193827 0.9844231  0.2082917  0.72019464 0.82877856\n",
      " 0.9863418  0.8872554  0.44446266 0.7806489  0.8750234  0.23741992\n",
      " 0.8983585  0.7165948  0.9739846  0.9964216  0.4880464  0.1630174\n",
      " 0.10335507 0.86905986 0.0195763  0.9862743  0.35286933 0.86951333\n",
      " 0.17001995 0.99511695 0.0548844  0.74113256 0.27338257 0.42292118\n",
      " 0.02201278 0.26019332 0.9931519  0.879421   0.45970052 0.57874525\n",
      " 0.7639403  0.94813967 0.30785805 0.7042128  0.06304399 0.98056567\n",
      " 0.09427007 0.23070796 0.99146175 0.57405144 0.853379   0.638952\n",
      " 0.9917148  0.18180294 0.9935482  0.8829428  0.9977393  0.9354529\n",
      " 0.9434435  0.02891248 0.3809025  0.98627496 0.97107273 0.7354243\n",
      " 0.51467085 0.09018853 0.14318304 0.98714995 0.64263254 0.02442526\n",
      " 0.9405811  0.42039132 0.9276756  0.6978497  0.47170874 0.98966557\n",
      " 0.38980666 0.0193025  0.9786274  0.48055813 0.42139888 0.99039793\n",
      " 0.82632464 0.3278629  0.15940894 0.32809722 0.763084   0.45093423\n",
      " 0.765189   0.43569896 0.7015068  0.03052624 0.07095808 0.138488\n",
      " 0.98810846 0.5910902  0.929683   0.11939523 0.5130913  0.2863983\n",
      " 0.28691223 0.5248324  0.875889   0.15144129 0.5439733  0.90300405\n",
      " 0.6804208  0.01986129 0.93455833 0.02362831 0.5632565  0.1137827\n",
      " 0.57823807 0.46981758 0.97210556 0.49638718 0.02699555 0.9880094\n",
      " 0.6100278  0.75107855 0.5037229  0.43677613 0.86152697 0.99891925\n",
      " 0.04689379 0.37110022 0.8252478  0.30552465 0.33818787 0.85289955\n",
      " 0.02912528 0.00840618 0.6956792  0.39407238 0.03282985 0.1105593\n",
      " 0.5839071  0.09900916 0.16472416 0.973083   0.47686064 0.17026094\n",
      " 0.98498267 0.12953646 0.8581251  0.49453294 0.713745   0.63820046\n",
      " 0.03543381 0.37753594 0.50208586 0.7840146  0.30686232 0.04372152\n",
      " 0.45088544 0.47914153 0.22538534 0.99158806 0.05220577 0.9066267\n",
      " 0.02318918 0.03367116 0.576579   0.06505251 0.7881297  0.6945787\n",
      " 0.5175669  0.04062869 0.03981102 0.07744399 0.05592493 0.08938347\n",
      " 0.48083037 0.1370196  0.12955043 0.81373733 0.36623377 0.78019065\n",
      " 0.04916901 0.97686255 0.0610327  0.14454448 0.99090904 0.2749863\n",
      " 0.07240552 0.8030676  0.32840043 0.30569285 0.15349759 0.9287733 ]\n",
      "metrics 0.5776081424936387 0.65 0.41725768321513\n"
     ]
    }
   ],
   "source": [
    "# Undersampled data \n",
    "sensitivity, specificity, misclass = evaluate_xgboost(X_train_undersampled, y_train_undersampled, X_test, y_test)\n",
    "print('metrics', sensitivity, specificity, misclass)\n",
    "#0.5776081424936387 0.65 0.41725768321513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "223ae5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99948055 0.69417894 0.97564507 0.9486155  0.9844168  0.998679\n",
      " 0.9839199  0.9943626  0.9661778  0.8085253  0.99191576 0.96908027\n",
      " 0.3926043  0.9965109  0.14696804 0.97778773 0.99481624 0.6143122\n",
      " 0.70819813 0.99500763 0.9998746  0.999253   0.996367   0.99914944\n",
      " 0.9891663  0.95894927 0.9052356  0.99843496 0.97331965 0.92961997\n",
      " 0.99287355 0.9912152  0.99906677 0.97906816 0.99931324 0.74407965\n",
      " 0.999752   0.8698368  0.923955   0.7796674  0.99711573 0.9412356\n",
      " 0.65509856 0.9996233  0.8889628  0.5721253  0.802917   0.9489308\n",
      " 0.9965095  0.9901453  0.9904266  0.9985012  0.9998449  0.9622222\n",
      " 0.99790525 0.9322568  0.9942006  0.73094696 0.45636383 0.9566007\n",
      " 0.9261595  0.9818255  0.8741952  0.96627796 0.94162655 0.8632734\n",
      " 0.30927697 0.8339516  0.9912487  0.99760324 0.9970976  0.9703588\n",
      " 0.7971054  0.9973482  0.99331313 0.9799212  0.98471826 0.98778373\n",
      " 0.93565017 0.9867033  0.7314167  0.9597275  0.973169   0.9582998\n",
      " 0.97499585 0.1961178  0.9630274  0.9598197  0.9445113  0.9974565\n",
      " 0.9984428  0.999806   0.8573641  0.9912214  0.9958727  0.9706392\n",
      " 0.9830142  0.99957055 0.7518253  0.9569063  0.98234344 0.95915395\n",
      " 0.9870907  0.98816097 0.8370761  0.9112772  0.9775979  0.9990977\n",
      " 0.99157625 0.9974153  0.8107841  0.9969549  0.96024805 0.97247326\n",
      " 0.9733323  0.82962435 0.9192609  0.9335683  0.9944068  0.9638758\n",
      " 0.9567846  0.9888341  0.14822383 0.6895303  0.9399282  0.99457526\n",
      " 0.9945205  0.9972683  0.98969966 0.85508484 0.97723114 0.8122203\n",
      " 0.9816488  0.6717249  0.9682998  0.9973942  0.9770808  0.43141383\n",
      " 0.98339856 0.99683553 0.9910774  0.9845323  0.7004634  0.4194762\n",
      " 0.98547167 0.97649777 0.98997974 0.88242173 0.9991503  0.9640906\n",
      " 0.99821717 0.9355865  0.89774245 0.9992944  0.9172357  0.9785517\n",
      " 0.9952341  0.98170805 0.9995741  0.654606   0.9480212  0.99984133\n",
      " 0.9700383  0.9897299  0.8871121  0.94439113 0.996833   0.99443686\n",
      " 0.9884012  0.99618334 0.95785123 0.86483365 0.99382484 0.9956161\n",
      " 0.89751434 0.9868426  0.5465941  0.9868739  0.9945997  0.9898655\n",
      " 0.9938169  0.97581404 0.88309187 0.9736327  0.48959836 0.99373466\n",
      " 0.96208483 0.8550869  0.9358657  0.9879353  0.9042482  0.996872\n",
      " 0.9894912  0.691395   0.8671443  0.98219556 0.60944957 0.8422288\n",
      " 0.9958191  0.8339258  0.96483684 0.9659476  0.98517287 0.89830863\n",
      " 0.7158824  0.8795487  0.08701643 0.8387927  0.9965912  0.997626\n",
      " 0.97715294 0.9764707  0.97110975 0.9972639  0.9985551  0.99810624\n",
      " 0.9969277  0.97912574 0.89201707 0.987944   0.8749315  0.85919553\n",
      " 0.9782165  0.97815496 0.972281   0.996906   0.95465326 0.96091926\n",
      " 0.8488458  0.93114007 0.99734193 0.9627429  0.9746943  0.9762199\n",
      " 0.96251845 0.9481534  0.75339574 0.98125535 0.9315004  0.9751116\n",
      " 0.9866453  0.9831161  0.96625674 0.9777999  0.9206207  0.9988267\n",
      " 0.8784794  0.9021615  0.97238094 0.9680775  0.9958484  0.957288\n",
      " 0.92861515 0.9934569  0.99093527 0.97673315 0.99230593 0.98816943\n",
      " 0.9076076  0.7522122  0.99017125 0.9891561  0.9505057  0.98458683\n",
      " 0.99886847 0.99056596 0.9991141  0.997872   0.8492205  0.532256\n",
      " 0.9965019  0.76264966 0.98501253 0.78205776 0.97916406 0.95430684\n",
      " 0.9991405  0.9251534  0.36375633 0.9961612  0.96158636 0.97673905\n",
      " 0.9951799  0.92675275 0.9954601  0.99809104 0.9943679  0.8528436\n",
      " 0.9863819  0.9357352  0.95629954 0.997649   0.9851075  0.96789247\n",
      " 0.9743747  0.99597794 0.99892116 0.99738675 0.17338279 0.8364312\n",
      " 0.97014713 0.6639495  0.99890924 0.9941981  0.84639305 0.82784396\n",
      " 0.63838774 0.7818273  0.95894575 0.9963928  0.93762237 0.95732015\n",
      " 0.84870607 0.7243373  0.99363846 0.95983946 0.9871989  0.9574434\n",
      " 0.98324984 0.9814975  0.9033242  0.9921876  0.44900492 0.95296353\n",
      " 0.9981213  0.9944325  0.6134227  0.82731485 0.9959573  0.9973213\n",
      " 0.99522555 0.97559184 0.9963282  0.9836532  0.9171724  0.99218255\n",
      " 0.9437405  0.99889296 0.72853243 0.98881835 0.9896522  0.7419525\n",
      " 0.99648845 0.94318575 0.9992636  0.95680195 0.56000096 0.9870936\n",
      " 0.6540673  0.7212867  0.989838   0.99947125 0.9952272  0.5458172\n",
      " 0.99951386 0.9961093  0.979458   0.7780635  0.9121064  0.978227\n",
      " 0.95396996 0.74742144 0.9754834  0.9624945  0.3286458  0.33311087\n",
      " 0.99970526 0.99960476 0.9925839  0.96861726 0.9911566  0.97196215\n",
      " 0.99829453 0.8373711  0.18774082 0.47927147 0.9945445  0.7469021\n",
      " 0.842327   0.8248315  0.9199224  0.9990926  0.999603   0.9291583\n",
      " 0.965762   0.8978743  0.9759641  0.98989713 0.3838387  0.6056984\n",
      " 0.99403197 0.9997522  0.97773474 0.9981012  0.9141476  0.9620028\n",
      " 0.94695324 0.96362656 0.96581596 0.98437774 0.9186898  0.9181472\n",
      " 0.91887736 0.8389739  0.9972256  0.9977089  0.9969302  0.97489136\n",
      " 0.69759953 0.989301   0.99443084 0.7913448  0.99886996 0.9956281\n",
      " 0.96788424 0.90711623 0.9986349  0.9521354  0.91408974 0.9974394\n",
      " 0.9993192  0.6436885  0.99438345 0.97017676 0.8997395  0.99163276\n",
      " 0.7613196  0.9986914  0.9980241  0.9992312  0.9649868  0.9859686\n",
      " 0.97554237 0.5390889  0.9603648  0.7923899  0.99974173 0.9471613\n",
      " 0.98285264 0.8677474  0.97692704 0.99773574 0.5360789  0.9902863\n",
      " 0.99431807 0.99689096 0.9982191  0.98822814 0.9914034  0.99856657\n",
      " 0.9951742  0.9876859  0.99737155 0.999373   0.6228962  0.98465663\n",
      " 0.8733631  0.9355615  0.9435095  0.96908754 0.9865813  0.9973646\n",
      " 0.8938479  0.9967006  0.93309915 0.999564   0.990657   0.87755793\n",
      " 0.92122304 0.99341923 0.9995646  0.6055908  0.6259624  0.9670333\n",
      " 0.45329165 0.8801328  0.7907499  0.8636452  0.8992316  0.9917474\n",
      " 0.72119766 0.9402108  0.8102815  0.99004585 0.97334325 0.9326221\n",
      " 0.9818934  0.7887911  0.99451584 0.9664461  0.6185374  0.5211589\n",
      " 0.92095125 0.80164623 0.9997727  0.9956448  0.98796034 0.5021402\n",
      " 0.99954444 0.957137   0.9961499  0.9924428  0.9830809  0.9914836\n",
      " 0.98681045 0.96752864 0.98935705 0.96016186 0.96576047 0.54630226\n",
      " 0.9353163  0.95225364 0.9861237  0.9726293  0.9173749  0.89733297\n",
      " 0.90892804 0.9993926  0.8556951  0.97441745 0.98333424 0.9972652\n",
      " 0.99810743 0.64844257 0.99059767 0.9763365  0.7598316  0.99735355\n",
      " 0.7120523  0.988453   0.9859724  0.90810263 0.99977773 0.77014357\n",
      " 0.98556846 0.995713   0.98063344 0.92852575 0.99045134 0.9953543\n",
      " 0.9855364  0.98520803 0.92407125 0.9867975  0.9715048  0.99132055\n",
      " 0.9934818  0.9994344  0.99570185 0.9833009  0.9381344  0.9992017\n",
      " 0.91347915 0.9917082  0.9876599  0.8820073  0.9855422  0.9922611\n",
      " 0.30025074 0.82582337 0.9961902  0.865248   0.99829096 0.9970901\n",
      " 0.98346263 0.99990904 0.98574114 0.999017   0.9623685  0.96894306\n",
      " 0.99888057 0.88213944 0.99949014 0.5206751  0.9773311  0.7584949\n",
      " 0.83518505 0.9978284  0.99647045 0.96667874 0.9992574  0.9749844\n",
      " 0.9638995  0.9196459  0.9435962  0.9541481  0.9886473  0.97692466\n",
      " 0.9986065  0.9998976  0.99978036 0.99709547 0.62524945 0.996977\n",
      " 0.70400155 0.674954   0.997894   0.9765131  0.89595586 0.8994144\n",
      " 0.9651067  0.93578166 0.99744236 0.9383287  0.99260896 0.21444736\n",
      " 0.93902814 0.99701476 0.9582196  0.9988489  0.89754075 0.99674016\n",
      " 0.9805668  0.93411034 0.99796224 0.9996068  0.929547   0.9976799\n",
      " 0.42701808 0.84921974 0.7924783  0.9440781  0.9816325  0.6491767\n",
      " 0.6772767  0.9791702  0.48344833 0.9734263  0.9005649  0.98746234\n",
      " 0.8334076  0.9988889  0.6921201  0.9818829  0.9981365  0.9917338\n",
      " 0.9996038  0.99793905 0.8754199  0.9980957  0.9818527  0.95399576\n",
      " 0.9943507  0.9971359  0.55036604 0.13457812 0.85688895 0.9875273\n",
      " 0.97770655 0.9708645  0.79066294 0.59986913 0.99978584 0.86048186\n",
      " 0.9812304  0.9958692  0.7059882  0.92447615 0.96971905 0.73589075\n",
      " 0.9977366  0.963624   0.9998437  0.9962346  0.9851633  0.9968521\n",
      " 0.9977709  0.99373215 0.97837764 0.9886291  0.8014456  0.94899553\n",
      " 0.96351045 0.9905282  0.9993375  0.99997234 0.9868352  0.959153\n",
      " 0.89869523 0.9982698  0.7929305  0.9941525  0.85497016 0.9968376\n",
      " 0.98773205 0.9984762  0.97442526 0.89403856 0.9832683  0.7477892\n",
      " 0.93564004 0.96138155 0.99927264 0.14938276 0.9991074  0.98533964\n",
      " 0.99136025 0.9926675  0.7077244  0.98630863 0.8951111  0.9982461\n",
      " 0.96639466 0.97315264 0.9628135  0.99876535 0.9983494  0.93288624\n",
      " 0.9998957  0.6687129  0.9986143  0.99111134 0.9993419  0.9885571\n",
      " 0.9913816  0.99300945 0.8484909  0.9865954  0.99637115 0.92244226\n",
      " 0.93500495 0.98186594 0.8254913  0.991503   0.98428714 0.8343757\n",
      " 0.95778024 0.99338526 0.96606934 0.9664433  0.85030055 0.9980102\n",
      " 0.9269246  0.79929155 0.9968792  0.82718027 0.965538   0.9906375\n",
      " 0.9897299  0.90610963 0.809656   0.99345917 0.9869158  0.91300064\n",
      " 0.9945886  0.8965141  0.9971078  0.55074525 0.9930254  0.9144672\n",
      " 0.99830997 0.9573961  0.9999567  0.57511085 0.8781163  0.71526766\n",
      " 0.98035    0.9442321  0.91396713 0.99343747 0.97331685 0.99224746\n",
      " 0.7044345  0.26730546 0.99841094 0.60315776 0.99073434 0.8407154\n",
      " 0.990325   0.95379305 0.9850375  0.91530764 0.82531947 0.99888796\n",
      " 0.99344194 0.9798288  0.970676   0.98971075 0.9967025  0.9950147\n",
      " 0.7404515  0.9995907  0.98911905 0.99971265 0.638479   0.9963425\n",
      " 0.6954783  0.31609383 0.97168905 0.960005   0.9193234  0.2770576\n",
      " 0.8733482  0.6644253  0.66200423 0.9981754  0.8696492  0.6268959\n",
      " 0.9978878  0.5128858  0.94166714 0.94343853 0.8521667  0.96390116\n",
      " 0.8905026  0.9034171  0.8595493  0.9989172  0.6410915  0.17681839\n",
      " 0.9550852  0.9514557  0.7099743  0.9946466  0.9321506  0.9977449\n",
      " 0.20487922 0.90634143 0.9979704  0.8999482  0.9828708  0.95185125\n",
      " 0.9969764  0.7142463  0.31067106 0.80823904 0.7695039  0.4707692\n",
      " 0.9649081  0.29362148 0.8558858  0.960738   0.8941102  0.9936818\n",
      " 0.18348219 0.9994537  0.7633065  0.7886037  0.9992861  0.8152291\n",
      " 0.6472882  0.9920208  0.8912333  0.9971064  0.7130509  0.94957346]\n",
      "metrics 0.9669211195928753 0.13333333333333333 0.09219858156028371\n"
     ]
    }
   ],
   "source": [
    "# Oversampled data \n",
    "sensitivity, specificity, misclass = evaluate_xgboost(X_train_oversampled, y_train_oversampled, X_test, y_test)\n",
    "print('metrics', sensitivity, specificity, misclass)\n",
    "#0.9669211195928753 0.13333333333333333 0.09219858156028371"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "c34317ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9982999  0.95751095 0.93235874 0.67247653 0.9704598  0.9698229\n",
      " 0.85613257 0.9981463  0.97398925 0.6402799  0.9732387  0.5813303\n",
      " 0.89887595 0.99430746 0.44329336 0.61394364 0.9408942  0.649676\n",
      " 0.30808794 0.98177755 0.9997149  0.99986815 0.9299455  0.99477804\n",
      " 0.9812857  0.9951746  0.66545475 0.99145997 0.9796641  0.710858\n",
      " 0.8938956  0.9959959  0.997813   0.99890995 0.9461746  0.9437099\n",
      " 0.99702966 0.4079875  0.8533231  0.841605   0.9861668  0.97745836\n",
      " 0.75724167 0.9994167  0.37493464 0.93792814 0.9114156  0.9553289\n",
      " 0.9980824  0.9966798  0.99772567 0.9971987  0.99972016 0.9917127\n",
      " 0.9933206  0.41226423 0.9871885  0.81054676 0.12572484 0.85816187\n",
      " 0.7993977  0.92997956 0.36360887 0.93933827 0.88590485 0.96851593\n",
      " 0.23776862 0.85489136 0.99629885 0.9686886  0.9751799  0.97484493\n",
      " 0.55262446 0.9982224  0.99474394 0.9525643  0.8363729  0.99836594\n",
      " 0.8902972  0.9894688  0.9409363  0.9904484  0.98669565 0.9516597\n",
      " 0.6427118  0.19526163 0.9758446  0.66451234 0.9536584  0.9986916\n",
      " 0.94156694 0.9993401  0.9989906  0.9967933  0.99816483 0.78064686\n",
      " 0.99629956 0.83558255 0.48559326 0.9414104  0.81471074 0.61624444\n",
      " 0.9967456  0.99706036 0.5607661  0.55724394 0.9291124  0.9988682\n",
      " 0.9645574  0.99182665 0.45916528 0.98143977 0.97277844 0.99530953\n",
      " 0.8911318  0.8827541  0.9980319  0.50279826 0.9992238  0.41218764\n",
      " 0.953901   0.96369255 0.11768958 0.73400897 0.9902953  0.9928532\n",
      " 0.87541544 0.99901664 0.95736617 0.6169397  0.9102024  0.22113656\n",
      " 0.8364752  0.8941769  0.86060697 0.996232   0.9976827  0.3246579\n",
      " 0.45163506 0.9789121  0.9875372  0.9565786  0.9924954  0.49120614\n",
      " 0.8806618  0.92281365 0.99063444 0.34855756 0.9943587  0.9927719\n",
      " 0.99078345 0.8741531  0.9432609  0.99500364 0.94375396 0.9192126\n",
      " 0.9671272  0.98104274 0.99698466 0.14156954 0.9967899  0.99824\n",
      " 0.9908941  0.99545246 0.79239553 0.4857258  0.97173685 0.6884954\n",
      " 0.99598336 0.98825586 0.9900574  0.7334954  0.99707866 0.9847344\n",
      " 0.9542289  0.9977155  0.9569979  0.8696156  0.9976999  0.96101195\n",
      " 0.99704045 0.98585665 0.97418696 0.9672928  0.7533426  0.9793408\n",
      " 0.93644553 0.9166347  0.9945874  0.994436   0.8938053  0.9974112\n",
      " 0.66367126 0.3442344  0.28501698 0.9829197  0.13747329 0.93289626\n",
      " 0.99921167 0.7214785  0.63675267 0.9371423  0.8692552  0.84168565\n",
      " 0.55333215 0.8722276  0.0445761  0.54881936 0.9285936  0.9973679\n",
      " 0.99621636 0.9490608  0.90464133 0.99410534 0.9978941  0.9997565\n",
      " 0.99829847 0.9884113  0.9366874  0.20369416 0.2896314  0.8754554\n",
      " 0.9288313  0.99352276 0.977778   0.99854124 0.980605   0.99245995\n",
      " 0.3821651  0.97588694 0.99722457 0.9314623  0.9971961  0.8865846\n",
      " 0.8835126  0.99019027 0.84342533 0.95393276 0.9859781  0.93759984\n",
      " 0.9507901  0.98628473 0.9978186  0.6176469  0.979855   0.99695516\n",
      " 0.93195015 0.92489344 0.9889264  0.9894462  0.98893934 0.95225483\n",
      " 0.90012133 0.9845686  0.97333366 0.9904953  0.99798787 0.9358836\n",
      " 0.6442399  0.7828483  0.9403002  0.9767079  0.93671    0.9263765\n",
      " 0.9762607  0.9221652  0.9999331  0.94650555 0.9136177  0.56858134\n",
      " 0.9961133  0.33557653 0.9983012  0.9678895  0.70207417 0.9577085\n",
      " 0.97472614 0.7208422  0.6478384  0.9994319  0.75009763 0.96780115\n",
      " 0.99867815 0.9175516  0.9443049  0.9992525  0.9895119  0.6248117\n",
      " 0.9810721  0.9615922  0.7885227  0.9888847  0.99611497 0.99779737\n",
      " 0.988122   0.998302   0.99847716 0.9988417  0.12284742 0.9473638\n",
      " 0.64271736 0.8991471  0.9837293  0.99975806 0.8109483  0.975848\n",
      " 0.9304879  0.16145895 0.9804103  0.9974491  0.84495634 0.9423673\n",
      " 0.9210811  0.92865056 0.9947178  0.9908743  0.9939976  0.91677886\n",
      " 0.9802269  0.8477452  0.42187032 0.9809909  0.77167284 0.9760646\n",
      " 0.99937904 0.9769111  0.92221504 0.57230574 0.9987556  0.99881005\n",
      " 0.9540378  0.9767089  0.9973295  0.87366855 0.9518999  0.9973947\n",
      " 0.9639936  0.99219716 0.6507861  0.9484982  0.99347043 0.98716706\n",
      " 0.99968386 0.9872363  0.9999776  0.97646093 0.39271605 0.9969607\n",
      " 0.98488253 0.5702656  0.76234055 0.9999676  0.55021757 0.5429131\n",
      " 0.9981079  0.9165072  0.9935236  0.6894093  0.96581274 0.38700017\n",
      " 0.55318993 0.8674818  0.9278912  0.99517834 0.21439102 0.64483684\n",
      " 0.9984275  0.99740976 0.9996923  0.9969265  0.6144287  0.9978218\n",
      " 0.9985037  0.8849063  0.8740732  0.9444243  0.9987004  0.810069\n",
      " 0.9520952  0.9725958  0.86249053 0.99311185 0.99993026 0.97028905\n",
      " 0.96709913 0.89371485 0.99259514 0.92900276 0.49903145 0.07593885\n",
      " 0.93122023 0.99992514 0.98664993 0.99171454 0.91738504 0.9029627\n",
      " 0.7884613  0.9032709  0.24969687 0.98194665 0.952416   0.9957813\n",
      " 0.33683947 0.9416051  0.9945569  0.9426849  0.99435633 0.9225689\n",
      " 0.96579784 0.9976367  0.9442358  0.9122635  0.9778209  0.957824\n",
      " 0.99247724 0.95542896 0.98292    0.97587514 0.9289316  0.9994252\n",
      " 0.98399425 0.7723552  0.9718086  0.6653571  0.95148754 0.9927885\n",
      " 0.9187695  0.9872062  0.992376   0.9790509  0.98371476 0.93192023\n",
      " 0.9183272  0.21747234 0.9854364  0.85242736 0.99971634 0.9990804\n",
      " 0.99301296 0.96157664 0.9891355  0.9861529  0.55025685 0.9813719\n",
      " 0.9326402  0.9874614  0.99949193 0.9659403  0.9991708  0.9920608\n",
      " 0.9779748  0.999793   0.99951947 0.9958689  0.4944793  0.8126587\n",
      " 0.82961696 0.97010607 0.53460735 0.14273196 0.98925287 0.99563235\n",
      " 0.92419493 0.98954123 0.7339768  0.99916255 0.98756766 0.91172445\n",
      " 0.9957014  0.8663196  0.9992372  0.9285107  0.7370195  0.9824737\n",
      " 0.62871814 0.6571856  0.9641134  0.5625086  0.99354327 0.9943427\n",
      " 0.6151702  0.9446294  0.7994209  0.9976325  0.9291974  0.9600094\n",
      " 0.99245036 0.91900754 0.99479264 0.91784805 0.93816185 0.5916306\n",
      " 0.9953082  0.81241184 0.9994374  0.9227413  0.9893183  0.7246398\n",
      " 0.99736685 0.82973707 0.9965405  0.9828825  0.92085844 0.999246\n",
      " 0.9171174  0.90124035 0.9970861  0.9905391  0.9956398  0.5213549\n",
      " 0.9973563  0.92304915 0.9936824  0.89710855 0.9357436  0.27715328\n",
      " 0.99091655 0.9981781  0.20744012 0.79697996 0.9677173  0.9667271\n",
      " 0.97245955 0.6738524  0.9685716  0.86800724 0.3104285  0.97734374\n",
      " 0.66007674 0.98429894 0.9806481  0.76423484 0.9993007  0.959453\n",
      " 0.98876476 0.99798477 0.9350115  0.9572463  0.9983851  0.9919179\n",
      " 0.9990871  0.9975043  0.6780441  0.9885019  0.9863977  0.83861905\n",
      " 0.95617515 0.9961282  0.9970047  0.9805697  0.74249727 0.9998373\n",
      " 0.99142367 0.9859358  0.99545467 0.4988938  0.8555272  0.96827704\n",
      " 0.16151609 0.67605764 0.9974548  0.73626494 0.9935009  0.98936987\n",
      " 0.8475987  0.99695396 0.99846977 0.9951532  0.9188182  0.82556653\n",
      " 0.9896108  0.9864277  0.99941015 0.9668696  0.9619561  0.92294556\n",
      " 0.9398007  0.997981   0.9064204  0.998596   0.99952376 0.88027805\n",
      " 0.66583157 0.8501025  0.6833995  0.9328783  0.83978647 0.98667115\n",
      " 0.9960866  0.99969125 0.9990251  0.9990984  0.6967915  0.9978358\n",
      " 0.5048763  0.5601162  0.99822754 0.99048865 0.36824286 0.86261666\n",
      " 0.95395184 0.94155    0.9715341  0.47120965 0.96615314 0.757462\n",
      " 0.96742713 0.99791056 0.9766341  0.99219066 0.2448033  0.9987859\n",
      " 0.9943433  0.97049665 0.99727976 0.99982005 0.65541226 0.9994456\n",
      " 0.8956352  0.9160426  0.8537584  0.98064077 0.9756712  0.30672887\n",
      " 0.9538795  0.9928456  0.16285348 0.8559716  0.71123666 0.99249333\n",
      " 0.9164896  0.933038   0.9426097  0.9941064  0.99776506 0.9652245\n",
      " 0.99989843 0.99867153 0.30399683 0.99787307 0.9574329  0.98763937\n",
      " 0.992203   0.85075355 0.7201827  0.8370688  0.5636656  0.987255\n",
      " 0.9651343  0.88220084 0.95705825 0.8423668  0.9929611  0.30488595\n",
      " 0.9752594  0.9933072  0.91486037 0.99593544 0.8580155  0.3826911\n",
      " 0.9978295  0.93520695 0.9984415  0.9912158  0.93165195 0.99275535\n",
      " 0.99546826 0.9326689  0.95101815 0.9994288  0.98847187 0.8376337\n",
      " 0.87736595 0.96176    0.9996176  0.9999287  0.9892652  0.7812015\n",
      " 0.9749155  0.9986058  0.31636587 0.9516951  0.9211704  0.9986671\n",
      " 0.79009324 0.99345726 0.8528125  0.86565167 0.8384283  0.45251694\n",
      " 0.81365955 0.982298   0.9771474  0.64193034 0.97813696 0.9942556\n",
      " 0.8803217  0.9610878  0.952953   0.97680753 0.98551637 0.99423486\n",
      " 0.9597485  0.9456318  0.9834319  0.8071863  0.99733007 0.9915127\n",
      " 0.998777   0.75580895 0.9997569  0.96791524 0.9974819  0.9930225\n",
      " 0.67529076 0.98565835 0.856154   0.98206115 0.99541205 0.9269657\n",
      " 0.76848423 0.99106795 0.91906875 0.9421006  0.9770693  0.18616194\n",
      " 0.9827261  0.98950243 0.9664715  0.674623   0.9288786  0.9934957\n",
      " 0.9436167  0.9607141  0.9733166  0.96708953 0.988301   0.9917379\n",
      " 0.5460263  0.6739798  0.92703754 0.9579154  0.89142454 0.98752195\n",
      " 0.99160004 0.75840646 0.998806   0.58103645 0.96407884 0.8862723\n",
      " 0.99039066 0.9740414  0.9982918  0.33747667 0.9213606  0.97628367\n",
      " 0.97970563 0.9720953  0.5917527  0.997767   0.86599493 0.9202718\n",
      " 0.51293194 0.6281436  0.9998838  0.8014785  0.9799135  0.74793774\n",
      " 0.99950516 0.9983889  0.99356925 0.9265196  0.83244604 0.9995908\n",
      " 0.9852905  0.95933706 0.93311006 0.9705932  0.9923441  0.99743503\n",
      " 0.82216895 0.9847474  0.998833   0.9779726  0.589081   0.998882\n",
      " 0.10873895 0.5384894  0.99456704 0.9163587  0.89477444 0.7519846\n",
      " 0.51796865 0.1361389  0.0947364  0.9995401  0.66271347 0.18391398\n",
      " 0.98039824 0.2588463  0.95102465 0.49773285 0.8191     0.9174183\n",
      " 0.886127   0.63520855 0.9583682  0.94750106 0.15006773 0.056235\n",
      " 0.90788335 0.9895774  0.9645519  0.97966206 0.48107806 0.96716934\n",
      " 0.4110093  0.96613723 0.999969   0.3543642  0.6917626  0.41714856\n",
      " 0.99202055 0.7516519  0.20530497 0.9897634  0.96048623 0.1389279\n",
      " 0.95268124 0.5889161  0.7669912  0.86593425 0.10981136 0.9958509\n",
      " 0.2808198  0.99161774 0.7433352  0.9101472  0.9981667  0.89996105\n",
      " 0.37332547 0.9347605  0.50982404 0.9741111  0.04841494 0.5093162 ]\n",
      "metrics 0.926208651399491 0.3 0.11820330969267134\n"
     ]
    }
   ],
   "source": [
    "# SMOTE\n",
    "sensitivity, specificity, misclass = evaluate_xgboost(X_train_smote, y_train_smote, X_test, y_test)\n",
    "print('metrics', sensitivity, specificity, misclass)\n",
    "#0.926208651399491 0.3 0.11820330969267134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "99b78c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metrics 0.5368956743002544 0.3 0.458628841607565\n"
     ]
    }
   ],
   "source": [
    "# Emseble\n",
    "from collections import Counter\n",
    "\n",
    "def evaluate_xgboost(X_train, y_train, X_test):\n",
    "    xgb = XGBClassifier(random_state=42)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    y_pred = xgb.predict(X_test)\n",
    "    return y_pred\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for X_train_e, y_train_e in [(X_train_edata1, y_train_edata1), \n",
    "                            (X_train_edata2, y_train_edata2), \n",
    "                            (X_train_edata3, y_train_edata3)]:\n",
    "    y_pred = evaluate_xgboost(X_train_e, y_train_e, X_test)\n",
    "    predictions.append(y_pred)\n",
    "\n",
    "#combine predictions using a majority vote\n",
    "ensemble_predictions = []\n",
    "for i in range(len(X_test)):\n",
    "    votes = [pred[i] for pred in predictions]\n",
    "    majority_vote = Counter(votes).most_common(1)[0][0]\n",
    "    ensemble_predictions.append(majority_vote)\n",
    "    \n",
    "misclass = 1-accuracy_score(y_test, ensemble_predictions)\n",
    "sensitivity = recall_score(y_test, ensemble_predictions)\n",
    "conf_matrix = confusion_matrix(y_test, ensemble_predictions)\n",
    "specificty = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "\n",
    "print('metrics', sensitivity, specificity, misclass)\n",
    "#0.5216284987277354 0.2 0.12411347517730498"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "bd8372a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the balanced training set\n",
    "combined_undersampled_training_data = pd.concat([X_train_smote, y_train_smote], axis=1)\n",
    "combined_test_data = pd.concat([X_test, y_test], axis=1)\n",
    "#training_path = \"/Users/victorialu/Desktop/Datasets/bankruptcy_training.csv\"\n",
    "#testing_path = \"/Users/victorialu/Desktop/Datasets/bankruptcy_testing.csv\"\n",
    "\n",
    "training_path = \"/capstone_project/datasets/bankruptcy_training.csv\"\n",
    "testing_path = \"/capstone_project/datasets/bankruptcy_testing.csv\"\n",
    "\n",
    "combined_undersampled_training_data.to_csv(training_path, index=False)  # Set index=False to exclude row numbers\n",
    "combined_test_data.to_csv(testing_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "32038d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimenting with hreshold adjustment-not included in project\n",
    "\n",
    "thresholds = [0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.96, 0.97, 0.98]\n",
    "\n",
    "threshold_values = []\n",
    "accuracy_values = []\n",
    "precision_values = []\n",
    "sensitivity_values = []\n",
    "specificity_values = []\n",
    "\n",
    "for threshold in thresholds:\n",
    "    xgb = XGBClassifier(random_state=123)\n",
    "    xgb.fit(X_train, y_train)\n",
    "    \n",
    "    #get predicted probabilities for class 1\n",
    "    y_pred_prob = xgb.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    #adjust the threshold\n",
    "    y_pred = (y_pred_prob >= threshold).astype(int)\n",
    "    \n",
    "    #calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    true_negatives = conf_matrix[0, 0]\n",
    "    false_positives = conf_matrix[0, 1]\n",
    "    false_negatives = conf_matrix[1, 0]\n",
    "    true_positives = conf_matrix[1, 1]\n",
    "    sensitivity = true_positives / (true_positives + false_negatives)\n",
    "    specificity = true_negatives / (true_negatives + false_positives)\n",
    "    \n",
    "    #store values\n",
    "    threshold_values.append(threshold)\n",
    "    accuracy_values.append(accuracy)\n",
    "    precision_values.append(precision)\n",
    "    sensitivity_values.append(sensitivity)\n",
    "    specificity_values.append(specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ec628d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Threshold  Accuracy  Precision  Sensitivity  Specificity\n",
      "0       0.50  0.925532   0.928826     0.996183     0.000000\n",
      "1       0.60  0.924350   0.930788     0.992366     0.033333\n",
      "2       0.70  0.920804   0.931573     0.987277     0.050000\n",
      "3       0.80  0.914894   0.936430     0.974555     0.133333\n",
      "4       0.90  0.869976   0.938961     0.919847     0.216667\n",
      "5       0.95  0.795508   0.950073     0.823155     0.433333\n",
      "6       0.96  0.764775   0.950845     0.787532     0.466667\n",
      "7       0.97  0.703310   0.948074     0.720102     0.483333\n",
      "8       0.98  0.607565   0.946850     0.611959     0.550000\n"
     ]
    }
   ],
   "source": [
    "metrics_df = pd.DataFrame({\n",
    "    'Threshold': threshold_values,\n",
    "    'Accuracy': accuracy_values,\n",
    "    'Precision': precision_values,\n",
    "    'Sensitivity': sensitivity_values,\n",
    "    'Specificity': specificity_values\n",
    "})\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7297c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
